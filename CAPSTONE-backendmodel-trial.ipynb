{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ravdess filenames identifiers --\n",
    "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
    "Vocal channel (01 = speech, 02 = song).\n",
    "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 = fearful, 07 = disgust, 08 = surprised).\n",
    "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
    "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
    "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
    "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "import cv2\n",
    "import pickle\n",
    "import dlib\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install -q --upgrade imutils\n",
    "!pip install -q --upgrade dlib\n",
    "!pip install -q deepface\n",
    "from deepface import DeepFace\n",
    "from deepface.commons import functions\n",
    "import imutils\n",
    "!pip install -q face-alignment\n",
    "import face_alignment\n",
    "from imutils import face_utils\n",
    "\n",
    "from IPython.display import Image\n",
    "from google.colab.patches import cv2_imshow\n",
    "from imutils.face_utils import FaceAligner\n",
    "from imutils.face_utils import rect_to_bb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,\n",
    "# your files will be saved in your Google Drive!\n",
    "\n",
    "# the base Google Drive directory\n",
    "root_dir = \"/content/drive/My Drive/\"\n",
    "\n",
    "# choose where you want your project files to be saved\n",
    "project_folder = \"FERcapstone/\"\n",
    "\n",
    "def create_and_set_working_directory(project_folder):\n",
    "  # check if your project folder exists. if not, it will be created.\n",
    "  if os.path.isdir(root_dir + project_folder) == False:\n",
    "    os.mkdir(root_dir + project_folder)\n",
    "    print(root_dir + project_folder + ' did not exist but was created.')\n",
    "\n",
    "  # change the OS to use your project folder as the working directory\n",
    "  os.chdir(root_dir + project_folder)\n",
    "\n",
    "  # create a test file to make sure it shows up in the right place\n",
    "  !touch 'new_file_in_working_directory.txt'\n",
    "  print('\\nYour working directory was changed to ' + root_dir + project_folder + \\\n",
    "        \"\\n\\nAn empty text file was created there. You can also run !pwd to confirm the current working directory.\" )\n",
    "\n",
    "create_and_set_working_directory(project_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def VideoToFrame(videosfolder, framesfolder):\n",
    "    \n",
    "\n",
    "    cwd = os.getcwd()\n",
    "\n",
    "    videosd = os.path.join(cwd, videosfolder)\n",
    "    framesd = os.path.join(cwd, framesfolder)\n",
    "\n",
    "    # reading the vodeos in the directory\n",
    "    videolist = os.listdir(videosd)\n",
    "\n",
    "    # making the vids to frames \n",
    "    for i in range(0, len(videolist)):\n",
    "\n",
    "        print(\"Progress: {}/{}\".format(i+1, len(videolist)))\n",
    "        vtitle = os.path.join(*(videosd, videolist[i]))\n",
    "        emotion = int(videolist[i].split(\"-\")[2]) - 1\n",
    "\n",
    "        # makingthe directory for the frames\n",
    "        framedir = os.path.join(*(framesd, str(i)))\n",
    "        if not os.path.exists(framedir):\n",
    "            os.makedirs(framedir)\n",
    "\n",
    "        vidcap = cv2.VideoCapture(vtitle)\n",
    "        success,image = vidcap.read()\n",
    "        count = 0\n",
    "        success = True\n",
    "        while success:\n",
    "            idx = 'frame_' + str(count) + '.png'\n",
    "            frame_n = os.path.join(*(framedir, idx))\n",
    "\n",
    "            cv2.imwrite(frame_n, image)\n",
    "            success,image = vidcap.read()\n",
    "            count += 1\n",
    "\n",
    "\n",
    "        #recording the emotion annotations \n",
    "        emotionpickle = {\"emotion\": emotion}\n",
    "        with open(framedir + \"/emotion.pickle\", 'wb') as f:\n",
    "            pickle.dump(emotionpickle, f, protocol = 2)\n",
    "\n",
    "    #to control when conversion is ran\n",
    "def runconvert2frames():\n",
    "    VideoToFrame('dataset/TestVideos/', 'dataset/TestFrames/')\n",
    "    VideoToFrame('dataset/TrainingVideos/', 'dataset/TrainingFrames/')\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this section to initialize the backend variables and the model used for training\n",
    "\n",
    "project_directory = os.getcwd()\n",
    "print(\"Project directory: \", project_directory)\n",
    "\n",
    "\n",
    "startindex=0\n",
    "skip=0\n",
    "maxcount=1000\n",
    "framescount = 30\n",
    "# emption classes from ravdess \n",
    "numberemotions = 8\n",
    "emotions = np.zeros(numberemotions)\n",
    "\n",
    "# number of instances to get from the folder\n",
    "maxfolderinstances = 1000\n",
    "\n",
    "# frames being saved will ahve this resolutioon - \n",
    "frameresolution = [300, 300, 1]\n",
    "\n",
    "#start with this index when getting instances from the directory\n",
    "startindex = 0\n",
    "\n",
    "# number of instances to get from the directory \n",
    "maxarraycount = 1000\n",
    "\n",
    "# saving the pickled data every 500 processed folders\n",
    "savingindex = 500\n",
    "\n",
    "# face detector treshold\n",
    "detectorthreshold = 0.8\n",
    "\n",
    "\n",
    "'''\n",
    "modelFile = os.path.join(project_directory, \"models/opencv_face_detector_uint8.pb\")\n",
    "configFile = os.path.join(project_directory, \"models/opencv_face_detector.pbtxt\")\n",
    "face_detector = cv2.dnn.readNetFromTensorflow(modelFile, configFile)\n",
    "'''\n",
    "\n",
    "modelFile = os.path.join(project_directory, \"models/res10_300x300_ssd_iter_140000.caffemodel\")\n",
    "configFile = os.path.join(project_directory, \"models/deploy.prototxt.txt\")\n",
    "face_detector = cv2.dnn.readNetFromCaffe(configFile, modelFile)\n",
    "\n",
    "# ---- trying a different face detector from dlib to see if the issue is resolved\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# \n",
    "predictor = dlib.shape_predictor(os.path.join(project_directory, \"models/shape_predictor_68_face_landmarks.dat\"))\n",
    "\n",
    "# ---- also changing the face aligner to check is issue is resolved\n",
    "#fa = FaceAligner(predictor, desiredFaceWidth=int(frames_resolution[0]), desiredFaceHeight=int(frames_resolution[1]))\n",
    "#fa = FaceAligner(predictor, desiredFaceWidth = 64)\n",
    "fa = FaceAligner(predictor, desiredFaceWidth = 256)\n",
    "#fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False)\n",
    "\n",
    "\n",
    "# making the folders \n",
    "trainingframesfolder = os.path.join(project_directory, \"dataset/TrainingFrames\")\n",
    "testframesfolder = os.path.join(project_directory, \"dataset/TestFrames\")\n",
    "\n",
    "#using pickle to dave the data liek the tutorial \n",
    "trainingsavefolder = os.path.join(project_directory, \"dataset/resolution_{}x{}x{}_train.pickle\".format(frameresolution[0], frameresolution[1], frameresolution[2]))\n",
    "testsavefolder = os.path.join(project_directory, \"dataset/resolution_{}x{}x{}_test.pickle\".format(frameresolution[0], frameresolution[1], frameresolution[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehotencode(number, numemotions):\n",
    "    arraynp = np.zeros((1, numemotions), dtype=int)\n",
    "    arraynp[0][number] = 1\n",
    "    return arraynp[0]\n",
    "\n",
    "def getfolderdata(framesfolder, savefolder):\n",
    "    data = []\n",
    "\n",
    "    #sorting the frame folders in order from directory\n",
    "    framesfolders = sorted(os.listdir(framesfolder), key=int)\n",
    "\n",
    "    for i, foldername in enumerate(framesfolders):\n",
    "        \n",
    "        if i < startindex:\n",
    "            continue\n",
    "\n",
    "        if(i%savingindex==0 and i!=0):\n",
    "            with open(os.path.join(project_directory, savefolder), 'wb') as handle:\n",
    "                pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        folderpath = os.path.join(*(framesfolder, foldername))\n",
    "\n",
    "        # load emotion number for the annotation file in the folder\n",
    "        with open(os.path.join(*(folderpath, \"annotation.pickle\")), 'rb') as handle:\n",
    "            annotation = pickle.load(handle)\n",
    "\n",
    "        #getting the correct emotion pickle data\n",
    "        emotion = annotation[\"emotion\"]\n",
    "\n",
    "        # if directory exist and contain enough frames for 1 array\n",
    "        if (os.path.exists(folderpath)) and (len(os.listdir(folderpath)) - 1 >= framescount):\n",
    "\n",
    "            if(emotions[emotion] < maxcount):\n",
    "\n",
    "                # loop through all frames\n",
    "                length = len(os.listdir(folderpath)) - 1\n",
    "                framearrcount = 0\n",
    "                index = startindex\n",
    "                images = []\n",
    "                while (index < length) and (maxfolderinstances > framearrcount) :\n",
    "\n",
    "                    image_path = os.path.join(folderpath, \"frame_{}.png\".format(index))\n",
    "                    image = cv2.imread(image_path, 1)\n",
    "\n",
    "                    print(index)\n",
    "                    #(h, w) = image.shape[:2]\n",
    "\n",
    "                    # --- ALIGNINMENT AND FACE DETECTION DONE HERE USING DEEPFACE -- RETURNS A NUMPYARRAY --- FACE FOUND HERE AND ALIGNED\n",
    "                    faceobjects = DeepFace.extract_faces(img_path = image, target_size = (300, 300), enforce_detection=False)\n",
    "\n",
    "                    for faceobject in faceobjects:\n",
    "                      img = faceobject[\"face\"]\n",
    "                      detectedface = img.copy()\n",
    "\n",
    "                      if detectedface.size != 0:\n",
    "\n",
    "                         # resize and normalization done at this step \n",
    "                        if(frameresolution[2] == 1):\n",
    "\n",
    "                          detectedface = cv2.cvtColor(detectedface, cv2.COLOR_BGR2GRAY)\n",
    "                          # detectedface = cv2.resize(detectedface, (frameresolution[0], framesresolution[1]))\n",
    "                          detectedface = cv2.normalize(detectedface, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "                          images.append(detectedface)\n",
    "                          #plt.imshow(detectedface)\n",
    "                          #plt.show()\n",
    "\n",
    "                          # skip 'skip' next frames\n",
    "                          index += skip\n",
    "\n",
    "                    index += 1\n",
    "\n",
    "\n",
    "                    # if True, saves array of 'framescount' images\n",
    "                    if len(images) == framescount:\n",
    "                        item = {\"emotion\": np.asarray(onehotencode(emotion, numberemotions)), \"images\": np.asarray(images)}\n",
    "                        images = []\n",
    "                        framearrcount += 1\n",
    "                        emotions[emotion] += 1\n",
    "                        data.append(item)\n",
    "\n",
    "                    if (framearrcount >= maxarraycount):\n",
    "                        break\n",
    "\n",
    "                print(\"--progress-- {}/{} \\t emotion added: \\t emotion: {} \\t{} arrays of {} images\".format(i, len(framesfolders), emotion, framearrcount, framescount))\n",
    "\n",
    "            else:\n",
    "                print(\"--progress-- {}/{} \\t emotion added: {} \\t emotion data limit reached\".format(i, len(framesfolders), emotion))\n",
    "\n",
    "        else:\n",
    "            print(\" Error with the directory - make sure directory exsists\")\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add flipped emotion -- adds more data for the chosen emotion index -- follows ravdess emotion index\n",
    "def flipemotiondata(data, emotionindex):\n",
    "    for item in list(data):\n",
    "        eindex = np.where(item[\"emotion\"] == 1)[0][0]\n",
    "        if eindex == emotionindex:\n",
    "            flippedarray = []\n",
    "            for image in item[\"images\"]:\n",
    "                flippedarray.append(cv2.flip(image, 0))\n",
    "            flippedarray = np.asarray(flippedarray)\n",
    "            newflipped = {\"emotion\": item[\"emotion\"], \"images\": flippedarray}\n",
    "            data.append(newflipped)\n",
    "\n",
    "\n",
    "\n",
    "# to measure how the emotion data is distributed among the emotions \n",
    "def datadistibution(data):\n",
    "    emotiondata = np.array([x[\"emotion\"] for x in data])\n",
    "    emotions = np.zeros(numberemotions)\n",
    "    for i, x in enumerate(emotiondata):\n",
    "        index = np.where(x == 1)[0][0]\n",
    "        emotions[index] += 1\n",
    "\n",
    "    return emotions\n",
    "\n",
    "\n",
    "# need to call before saving the data depending on the maximum count allowed \n",
    "def predatasave(data, maxcount):\n",
    "    shuffdata = np.asarray(data)\n",
    "    np.random.shuffle(shuffdata)\n",
    "    #making the emotion\n",
    "    resultdata = []\n",
    "    emotions = np.zeros(numberemotions)\n",
    "    emotiondata = np.array([x[\"emotion\"] for x in shuffdata])\n",
    "\n",
    "    for j in range(0, len(shuffdata)):\n",
    "        index = np.where(emotiondata[j] == 1)[0][0]\n",
    "\n",
    "        if emotions[index] < maxcount:\n",
    "            emotion = np.zeros(numberemotions)\n",
    "            emotion[index] = 1\n",
    "            sample = shuffdata[j]\n",
    "            sample[\"emotion\"] = emotion\n",
    "            resultdata.append(sample)\n",
    "            emotions[index] += 1\n",
    "\n",
    "    print(\"d]distribution of the data depending on emotion: \", emotions)\n",
    "    return resultdata\n",
    "\n",
    "\n",
    "\n",
    "#if presavedata works, call this to saave the input data to a pickle file - follow tutorial\n",
    "def datasave(data, filename):\n",
    "    filename = os.path.join(project_directory,\"dataset/{}\".format(filename))\n",
    "    with open(filename, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call the methods sequentially to track errors \n",
    "\n",
    "testingdata = getfolderdata(testframesfolder, testsavefolder)\n",
    "trainingdata = getfolderdata(trainingframesfolder, trainingsavefolder)\n",
    "\n",
    "print(\"data distribution -\")\n",
    "\n",
    "#looking at the emotions distribution for the test and training data based on emotions\n",
    "print(\"train data -\")\n",
    "print(datadistibution(trainingdata))\n",
    "print(\"test data -\")\n",
    "print(datadistibution(testingdata))\n",
    "\n",
    "\n",
    "#to even out the emotionsdata for the eneutral emotion -- emotion index 0\n",
    "print(\"Neutral emotion data getting flipped..\")\n",
    "flipemotiondata(trainingdata, 0)\n",
    "flipemotiondata(testingdata, 0)\n",
    "\n",
    "#looking at the emotion distribution after adding more Neutral emotion data \n",
    "print(\"data distribution -- post data flip\")\n",
    "print(\"train data -\")\n",
    "print(datadistibution(trainingdata))\n",
    "print(\"test data -\")\n",
    "print(datadistibution(testingdata))\n",
    "\n",
    "\n",
    "#to control the max amount of data read -- THIS EFFECTS THE PICKLE DATA SAVE\n",
    "numbertraindata = 500\n",
    "numbertestdata = 24\n",
    "\n",
    "# form\n",
    "test_data_4_save = predatasave(testingdata, numbertestdata)\n",
    "train_data_4_save = predatasave(trainingdata, numbertraindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# performing save in a deperate block\n",
    "datasave(test_data_4_save, \"resolution_{}x{}x{}__{}__TESTdata.pickle\".format(frameresolution[0], frameresolution[1], frameresolution[2], numbertestdata))\n",
    "datasave(train_data_4_save, \"resolution_{}x{}x{}__{}__TRAINdata.pickle\".format(frameresolution[0], frameresolution[1], frameresolution[2], numbertraindata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#once the pickle data is paclaged and save din the correct directory - using the pickled data ot train the model\n",
    "\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import keras\n",
    "\n",
    "#to access the pickle files\n",
    "folderpath = os.getcwd()\n",
    "print(\" current project directory: \", folderpath)\n",
    "\n",
    "#double check the name of the picklek files -- they change as the parameters of the data count change \n",
    "train_path = \"dataset/resolution_300x300x1__500__TRAINdata.pickle\"\n",
    "test_path = \"dataset/resolution_300x300x1__24__TESTdata.pickle\"\n",
    "emotions_count = 8\n",
    "\n",
    "\n",
    "\n",
    "#following pickle file model training tutorial for this part\n",
    "def splitemotionimage(data):\n",
    "    image = []\n",
    "    emotion = []\n",
    "    for item in data:\n",
    "        for i in range(0, len(item[\"images\"]), 1):\n",
    "            image.append(np.expand_dims(item[\"images\"][i],axis=3))\n",
    "            emotion.append(item[\"emotion\"])\n",
    "    return np.asarray(image), np.asarray(emotion)\n",
    "\n",
    "\n",
    "#loading pickle data  \n",
    "\n",
    "with open(os.path.join(folderpath, test_path), 'rb') as handle:\n",
    "        testingpickledata = pickle.load(handle)\n",
    "with open(os.path.join(folderpath, train_path), 'rb') as handle:\n",
    "        trainingpickledata = pickle.load(handle)\n",
    "\n",
    "#i-image, f-frame -- splitting the test and train pickle data \n",
    "iTEST, fTEST = splitemotionimage(testingpickledata)\n",
    "iTRAIN, fTRAIN = splitemotionimage(trainingpickledata)\n",
    "\n",
    "\n",
    "#making model and training params \n",
    "modelpath = \"models/BaseEmotionClassifyModel.hdf5\"\n",
    "model = load_model(modelpath, compile=False)\n",
    "learnrate = 0.005\n",
    "numepochs = 10\n",
    "batchsize = 8\n",
    "decayrate = 0.01\n",
    "momentrate = 0.9 \n",
    "\n",
    "#choosing sgd jsut for the initial testing \n",
    "sgd = keras.optimizers.SGD(lr=learnrate, momentum=momentrate, nesterov=True, decay=decayrate)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.fit(iTRAIN,fTRAIN, epochs=numepochs, validation_data=(iTEST, fTEST), batch_size=batchsize)\n",
    "\n",
    "#saving the new model to be used for testing\n",
    "#changes the version that is saved everytime it it run\n",
    "\n",
    "anotherindex = 0\n",
    "newname = \"models/EmotionClassifyVersion_{}.hdf5\".format(anotherindex)\n",
    "newname = os.path.join(folderpath, newname)\n",
    "\n",
    "model.save(newname)\n",
    "print(\" new model saved as {}\".format(newname))\n",
    "anotherindex = anotherindex+1\n",
    "       "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
